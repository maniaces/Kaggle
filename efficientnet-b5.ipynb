{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "from kaggle_datasets import KaggleDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Data access\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 12\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "IMAGE_SIZE = [1024, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_path(pre):\n",
    "    return np.vectorize(lambda file: os.path.join(GCS_DS_PATH, pre, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f227f7e0a50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')\n",
    "\n",
    "CLASSES = [0,1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 33126 training images, 10982 unlabeled test images\n"
     ]
    }
   ],
   "source": [
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        #\"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    #label = tf.cast(example['class'], tf.int32)\n",
    "    label = tf.cast(example['target'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['image_name']\n",
    "    return image, idnum # returns a dataset of image(s)\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "def data_augment(image, label):\n",
    "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
    "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
    "    # of the TPU while the TPU itself is computing gradients.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    #image = tf.image.random_saturation(image, 0, 2)\n",
    "    return image, label   \n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(ordered=False):\n",
    "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "print('Dataset: {} training images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lrfn(lr_start=0.00001, lr_max=0.0001, \n",
    "               lr_min=0.000001, lr_rampup_epochs=20, \n",
    "               lr_sustain_epochs=0, lr_exp_decay=.8):\n",
    "    lr_max = lr_max * strategy.num_replicas_in_sync\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    return lrfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "115515392/115515256 [==============================] - 5s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b5 (Model)      (None, 32, 32, 2048)      28513520  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,300,849\n",
      "Trainable params: 31,128,113\n",
      "Non-trainable params: 172,736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        efn.EfficientNetB5(\n",
    "            input_shape=(*IMAGE_SIZE, 3),\n",
    "            #weights='imagenet',\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        ),\n",
    "        L.GlobalAveragePooling2D(),\n",
    "        L.Dense(1024, activation = 'relu'), \n",
    "        L.Dropout(0.3), \n",
    "        L.Dense(512, activation= 'relu'), \n",
    "        L.Dropout(0.2), \n",
    "        L.Dense(256, activation='relu'), \n",
    "        L.Dropout(0.2), \n",
    "        L.Dense(128, activation='relu'), \n",
    "        L.Dropout(0.1), \n",
    "        L.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    #loss = 'binary_crossentropy',\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.1),\n",
    "    metrics=['binary_crossentropy']\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrfn = build_lrfn()\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 517 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/12\n",
      "517/517 [==============================] - 791s 2s/step - loss: 0.2924 - binary_crossentropy: 0.1818\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 4.95e-05.\n",
      "Epoch 2/12\n",
      "517/517 [==============================] - 583s 1s/step - loss: 0.2442 - binary_crossentropy: 0.1119\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 8.9e-05.\n",
      "Epoch 3/12\n",
      "517/517 [==============================] - 581s 1s/step - loss: 0.2414 - binary_crossentropy: 0.1067\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0001285.\n",
      "Epoch 4/12\n",
      "517/517 [==============================] - 582s 1s/step - loss: 0.2404 - binary_crossentropy: 0.1108\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000168.\n",
      "Epoch 5/12\n",
      "517/517 [==============================] - 583s 1s/step - loss: 0.2394 - binary_crossentropy: 0.1053\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00020749999999999998.\n",
      "Epoch 6/12\n",
      "517/517 [==============================] - 582s 1s/step - loss: 0.2392 - binary_crossentropy: 0.1028\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.000247.\n",
      "Epoch 7/12\n",
      "517/517 [==============================] - 582s 1s/step - loss: 0.2375 - binary_crossentropy: 0.1067\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0002865.\n",
      "Epoch 8/12\n",
      "517/517 [==============================] - 583s 1s/step - loss: 0.2369 - binary_crossentropy: 0.1007\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.000326.\n",
      "Epoch 9/12\n",
      "517/517 [==============================] - 582s 1s/step - loss: 0.2361 - binary_crossentropy: 0.1042\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0003655.\n",
      "Epoch 10/12\n",
      "517/517 [==============================] - 582s 1s/step - loss: 0.2353 - binary_crossentropy: 0.0963\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000405.\n",
      "Epoch 11/12\n",
      "517/517 [==============================] - 581s 1s/step - loss: 0.2352 - binary_crossentropy: 0.0921\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0004445.\n",
      "Epoch 12/12\n",
      "517/517 [==============================] - 582s 1s/step - loss: 0.2336 - binary_crossentropy: 0.0973\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    get_training_dataset(), \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[lr_schedule],\n",
    "    steps_per_epoch=STEPS_PER_EPOCH\n",
    "    #validation_data=valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"efficientnetb5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(get_training_dataset(), steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions...\n"
     ]
    }
   ],
   "source": [
    "test_ds = get_test_dataset(ordered=True)\n",
    "\n",
    "print('Computing predictions...')\n",
    "test_images_ds = test_ds.map(lambda image, idnum: image)\n",
    "probabilities = model.predict(test_images_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission.csv file...\n"
     ]
    }
   ],
   "source": [
    "print('Generating submission.csv file...')\n",
    "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
    "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6381819</td>\n",
       "      <td>0.340562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5583376</td>\n",
       "      <td>0.084019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_6408546</td>\n",
       "      <td>0.070527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_6932354</td>\n",
       "      <td>0.087256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8191278</td>\n",
       "      <td>0.149346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_6381819  0.340562\n",
       "1  ISIC_5583376  0.084019\n",
       "2  ISIC_6408546  0.070527\n",
       "3  ISIC_6932354  0.087256\n",
       "4  ISIC_8191278  0.149346"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame({'image_name': test_ids, 'target': np.concatenate(probabilities)})\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  target\n",
       "0  ISIC_0052060       0\n",
       "1  ISIC_0052349       0\n",
       "2  ISIC_0058510       0\n",
       "3  ISIC_0073313       0\n",
       "4  ISIC_0073502       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.080987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.076095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.074774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.078618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.119621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_0052060  0.080987\n",
       "1  ISIC_0052349  0.076095\n",
       "2  ISIC_0058510  0.074774\n",
       "3  ISIC_0073313  0.078618\n",
       "4  ISIC_0073502  0.119621"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sub['target']\n",
    "sub = sub.merge(pred_df, on='image_name')\n",
    "#sub.to_csv('submission_label_smoothing.csv', index=False)\n",
    "sub.to_csv('submission_b5.csv', index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
