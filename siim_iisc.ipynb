{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import efficientnet.tfkeras as efn\n",
    "import dill\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "print('Running on TPU ', tpu.master())\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tf.dataset\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Data access\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('melanoma-384x384')\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "AUG_BATCH = BATCH_SIZE\n",
    "IMAGE_SIZE = [384, 384]\n",
    "# Seed\n",
    "SEED = 333\n",
    "# Learning rate\n",
    "LR = 1e-5\n",
    "# cutmix prob\n",
    "cutmix_rate = 0.30\n",
    "\n",
    "# training filenames directory\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')\n",
    "# test filenames directory\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')\n",
    "# submission file\n",
    "submission = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear = math.pi * shear / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n",
    "    \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "def transform(image, label):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    DIM = IMAGE_SIZE[0]\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    if 0.5 > tf.random.uniform([1], minval = 0, maxval = 1):\n",
    "        rot = 15. * tf.random.normal([1],dtype='float32')\n",
    "    else:\n",
    "        rot = 180. * tf.random.normal([1],dtype='float32')\n",
    "    if 0.5 > tf.random.uniform([1], minval = 0, maxval = 1):\n",
    "        shr = 5. * tf.random.normal([1],dtype='float32') \n",
    "    else:\n",
    "        shr = 2. * tf.random.normal([1],dtype='float32')\n",
    "    if 0.5 > tf.random.uniform([1], minval = 0, maxval = 1):\n",
    "        h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10. \n",
    "    else:\n",
    "        h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/8.\n",
    "    if 0.5 > tf.random.uniform([1], minval = 0, maxval = 1):\n",
    "        w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10. \n",
    "    else:\n",
    "        w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/8.\n",
    "    if 0.5 > tf.random.uniform([1], minval = 0, maxval = 1):\n",
    "        h_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "    else:\n",
    "        h_shift = 8. * tf.random.normal([1],dtype='float32')\n",
    "    if 0.5 > tf.random.uniform([1], minval = 0, maxval = 1):\n",
    "        w_shift = 16. * tf.random.normal([1],dtype='float32') \n",
    "    else:\n",
    "        w_shift = 8. * tf.random.normal([1],dtype='float32')\n",
    "  \n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image['inp1'],tf.transpose(idx3))\n",
    "        \n",
    "    return {'inp1': tf.reshape(d,[DIM,DIM,3]), 'inp2': image['inp2']}, label\n",
    "\n",
    "# function to apply cutmix augmentation\n",
    "def cutmix(image, label):\n",
    "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
    "    # output - a batch of images with cutmix applied\n",
    "    \n",
    "    DIM = IMAGE_SIZE[0]    \n",
    "    imgs = []; labs = []\n",
    "    \n",
    "    for j in range(BATCH_SIZE):\n",
    "        \n",
    "        #random_uniform( shape, minval=0, maxval=None)        \n",
    "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
    "        P = tf.cast(tf.random.uniform([], 0, 1) <= cutmix_rate, tf.int32)\n",
    "        \n",
    "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
    "        k = tf.cast(tf.random.uniform([], 0, BATCH_SIZE), tf.int32)\n",
    "        \n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast(tf.random.uniform([], 0, DIM), tf.int32)\n",
    "        y = tf.cast(tf.random.uniform([], 0, DIM), tf.int32)\n",
    "        \n",
    "        # Beta(1, 1)\n",
    "        b = tf.random.uniform([], 0, 1) # this is beta dist with alpha=1.0\n",
    "        \n",
    "\n",
    "        WIDTH = tf.cast(DIM * tf.math.sqrt(1-b),tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        \n",
    "        # MAKE CUTMIX IMAGE\n",
    "        one = image['inp1'][j,ya:yb,0:xa,:]\n",
    "        two = image['inp1'][k,ya:yb,xa:xb,:]\n",
    "        three = image['inp1'][j,ya:yb,xb:DIM,:]        \n",
    "        #ya:yb\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "\n",
    "        img = tf.concat([image['inp1'][j,0:ya,:,:],middle,image['inp1'][j,yb:DIM,:,:]],axis=0)\n",
    "        imgs.append(img)\n",
    "        \n",
    "        # MAKE CUTMIX LABEL\n",
    "        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n",
    "        lab1 = label[j,]\n",
    "        lab2 = label[k,]\n",
    "        labs.append((1-a)*lab1 + a*lab2)\n",
    "\n",
    "    image2 = tf.reshape(tf.stack(imgs),(BATCH_SIZE,DIM,DIM,3))\n",
    "    label2 = tf.reshape(tf.stack(labs),(BATCH_SIZE, 1))\n",
    "    return {'inp1': image2, 'inp2': image['inp2']}, label2\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "# function to decode our images (normalize and reshape)\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    # convert image to floats in [0, 1] range\n",
    "    image = tf.cast(image, tf.float32) / 255.0 \n",
    "    # explicit size needed for TPU\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "# this function parse our images and also get the target variable\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        # tf.string means bytestring\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "        # shape [] means single element\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        # meta features\n",
    "        \"age_approx\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"sex\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"anatom_site_general_challenge\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        \n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['target'], tf.float32)\n",
    "    # meta features\n",
    "    data = {}\n",
    "    data['age_approx'] = tf.cast(example['age_approx'], tf.int32)\n",
    "    data['sex'] = tf.cast(example['sex'], tf.int32)\n",
    "    data['anatom_site_general_challenge'] = tf.cast(tf.one_hot(example['anatom_site_general_challenge'], 7), tf.int32)\n",
    "    # returns a dataset of (image, label, data)\n",
    "    return image, label, data\n",
    "\n",
    "# this function parse our image and also get our image_name (id) to perform predictions\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        # tf.string means bytestring\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "        # shape [] means single element\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        # meta features\n",
    "        \"age_approx\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"sex\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"anatom_site_general_challenge\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    image_name = example['image_name']\n",
    "    # meta features\n",
    "    data = {}\n",
    "    data['age_approx'] = tf.cast(example['age_approx'], tf.int32)\n",
    "    data['sex'] = tf.cast(example['sex'], tf.int32)\n",
    "    data['anatom_site_general_challenge'] = tf.cast(tf.one_hot(example['anatom_site_general_challenge'], 7), tf.int32)\n",
    "    # returns a dataset of (image, key, data)\n",
    "    return image, image_name, data\n",
    "    \n",
    "def load_dataset(filenames, labeled = True, ordered = False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # Diregarding data order. Order does not matter since we will be shuffling the data anyway\n",
    "    \n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        # disable order, increase speed\n",
    "        ignore_order.experimental_deterministic = False \n",
    "        \n",
    "    # automatically interleaves reads from multiple files\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    # use data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    # returns a dataset of (image, label) pairs if labeled = True or (image, id) pair if labeld = False\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls = AUTO) \n",
    "    return dataset\n",
    "\n",
    "# function for training and validation dataset\n",
    "def setup_input1(image, label, data):\n",
    "    \n",
    "    # get anatom site general challenge vectors\n",
    "    anatom = [tf.cast(data['anatom_site_general_challenge'][i], dtype = tf.float32) for i in range(7)]\n",
    "    \n",
    "    tab_data = [tf.cast(data[tfeat], dtype = tf.float32) for tfeat in ['age_approx', 'sex']]\n",
    "    \n",
    "    tabular = tf.stack(tab_data + anatom)\n",
    "    \n",
    "    return {'inp1': image, 'inp2':  tabular}, label\n",
    "\n",
    "# function for the test set\n",
    "def setup_input2(image, image_name, data):\n",
    "    \n",
    "    # get anatom site general challenge vectors\n",
    "    anatom = [tf.cast(data['anatom_site_general_challenge'][i], dtype = tf.float32) for i in range(7)]\n",
    "    \n",
    "    tab_data = [tf.cast(data[tfeat], dtype = tf.float32) for tfeat in ['age_approx', 'sex']]\n",
    "    \n",
    "    tabular = tf.stack(tab_data + anatom)\n",
    "    \n",
    "    return {'inp1': image, 'inp2':  tabular}, image_name\n",
    "\n",
    "# function for the validation (image name)\n",
    "def setup_input3(image, image_name, target, data):\n",
    "    \n",
    "    # get anatom site general challenge vectors\n",
    "    anatom = [tf.cast(data['anatom_site_general_challenge'][i], dtype = tf.float32) for i in range(7)]\n",
    "    \n",
    "    tab_data = [tf.cast(data[tfeat], dtype = tf.float32) for tfeat in ['age_approx', 'sex']]\n",
    "    \n",
    "    tabular = tf.stack(tab_data + anatom)\n",
    "    \n",
    "    return {'inp1': image, 'inp2':  tabular}, image_name, target\n",
    "\n",
    "def data_augment(data, label):\n",
    "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement \n",
    "    # in the next function (below), this happens essentially for free on TPU. \n",
    "    # Data pipeline code is executed on the \"CPU\" part\n",
    "    # of the TPU while the TPU itself is computing gradients.\n",
    "    data['inp1'] = tf.image.random_flip_left_right(data['inp1'])\n",
    "    data['inp1'] = tf.image.random_flip_up_down(data['inp1'])\n",
    "    data['inp1'] = tf.image.random_hue(data['inp1'], 0.01)\n",
    "    data['inp1'] = tf.image.random_saturation(data['inp1'], 0.7, 1.3)\n",
    "    data['inp1'] = tf.image.random_contrast(data['inp1'], 0.8, 1.2)\n",
    "    data['inp1'] = tf.image.random_brightness(data['inp1'], 0.1)\n",
    "    \n",
    "    return data, label\n",
    "\n",
    "def get_training_dataset(filenames, labeled = True, ordered = False):\n",
    "    dataset = load_dataset(filenames, labeled = labeled, ordered = ordered)\n",
    "    dataset = dataset.map(setup_input1, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.map(transform, num_parallel_calls = AUTO)\n",
    "    # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(filenames, labeled = True, ordered = True):\n",
    "    dataset = load_dataset(filenames, labeled = labeled, ordered = ordered)\n",
    "    dataset = dataset.map(setup_input1, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # using gpu, not enought memory to use cache\n",
    "    # dataset = dataset.cache()\n",
    "    # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    dataset = dataset.prefetch(AUTO) \n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(filenames, labeled = False, ordered = True):\n",
    "    dataset = load_dataset(filenames, labeled = labeled, ordered = ordered)\n",
    "    dataset = dataset.map(setup_input2, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    dataset = dataset.prefetch(AUTO) \n",
    "    return dataset\n",
    "\n",
    "# function to count how many photos we have in\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "# this function parse our images and also get the target variable\n",
    "def read_tfrecord_full(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string), \n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64), \n",
    "        # meta features\n",
    "        \"age_approx\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"sex\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"anatom_site_general_challenge\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    image_name = example['image_name']\n",
    "    target = tf.cast(example['target'], tf.float32)\n",
    "    # meta features\n",
    "    data = {}\n",
    "    data['age_approx'] = tf.cast(example['age_approx'], tf.int32)\n",
    "    data['sex'] = tf.cast(example['sex'], tf.int32)\n",
    "    data['anatom_site_general_challenge'] = tf.cast(tf.one_hot(example['anatom_site_general_challenge'], 7), tf.int32)\n",
    "    return image, image_name, target, data\n",
    "\n",
    "def load_dataset_full(filenames):        \n",
    "    # automatically interleaves reads from multiple files\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n",
    "    # returns a dataset of (image_name, target)\n",
    "    dataset = dataset.map(read_tfrecord_full, num_parallel_calls = AUTO) \n",
    "    return dataset\n",
    "\n",
    "def get_data_full(filenames):\n",
    "    dataset = load_dataset_full(filenames)\n",
    "    dataset = dataset.map(setup_input3, num_parallel_calls = AUTO)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "NUM_TRAINING_IMAGES = int(count_data_items(TRAINING_FILENAMES) * 0.8)\n",
    "# use validation data for training\n",
    "NUM_VALIDATION_IMAGES = int(count_data_items(TRAINING_FILENAMES) * 0.2)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
    "\n",
    "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "      \n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n",
    "               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    \n",
    "    with strategy.scope():\n",
    "        inp1 = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n",
    "        inp2 = tf.keras.layers.Input(shape = (9), name = 'inp2')\n",
    "        efnetb3 = efn.EfficientNetB3(weights = 'imagenet', include_top = False)\n",
    "        x = efnetb3(inp1)\n",
    "        x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "        x1 = tf.keras.layers.Dense(50)(inp2)\n",
    "        x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "        x1 = tf.keras.layers.Activation('relu')(x1)\n",
    "        concat = tf.keras.layers.concatenate([x, x1])\n",
    "        concat = tf.keras.layers.Dense(512, activation = 'relu')(concat)\n",
    "        concat = tf.keras.layers.BatchNormalization()(concat)\n",
    "        concat = tf.keras.layers.Dropout(0.2)(concat)\n",
    "        concat = tf.keras.layers.Dense(182, activation = 'relu')(concat)\n",
    "        concat = tf.keras.layers.BatchNormalization()(concat)\n",
    "        concat = tf.keras.layers.Dropout(0.15)(concat)\n",
    "        output = tf.keras.layers.Dense(1, activation = 'sigmoid')(concat)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = [inp1, inp2], outputs = [output])\n",
    "\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = LR)\n",
    "        # opt = tfa.optimizers.SWA(opt)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = opt,\n",
    "            loss = [binary_focal_loss(gamma = 2.0, alpha = 0.80)],\n",
    "            metrics = [tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()]\n",
    "        )\n",
    "\n",
    "        return model\n",
    "    \n",
    "def train_and_predict(SUB, folds = 5):\n",
    "    \n",
    "    models = []\n",
    "    oof_image_name = []\n",
    "    oof_target = []\n",
    "    oof_prediction = []\n",
    "    \n",
    "    # seed everything\n",
    "    seed_everything(SEED)\n",
    "\n",
    "    kfold = KFold(folds, shuffle = True, random_state = SEED)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(TRAINING_FILENAMES)):\n",
    "        print('\\n')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold + 1}')\n",
    "        train_dataset = get_training_dataset([TRAINING_FILENAMES[x] for x in trn_ind], labeled = True, ordered = False)\n",
    "        val_dataset = get_validation_dataset([TRAINING_FILENAMES[x] for x in val_ind], labeled = True, ordered = True)\n",
    "        K.clear_session()\n",
    "        model = get_model()\n",
    "        # using early stopping using val loss\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_auc', mode = 'max', patience = 5, \n",
    "                                                      verbose = 1, min_delta = 0.0001, restore_best_weights = True)\n",
    "        # lr scheduler\n",
    "        cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_auc', factor = 0.4, patience = 2, verbose = 1, min_delta = 0.0001, mode = 'max')\n",
    "        history = model.fit(train_dataset, \n",
    "                            steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                            epochs = EPOCHS,\n",
    "                            callbacks = [early_stopping, cb_lr_schedule],\n",
    "                            validation_data = val_dataset,\n",
    "                            verbose = 2)\n",
    "        models.append(model)\n",
    "        \n",
    "        # want to predict the validation set and save them for stacking\n",
    "        number_of_files = count_data_items([TRAINING_FILENAMES[x] for x in val_ind])\n",
    "        dataset = get_data_full([TRAINING_FILENAMES[x] for x in val_ind])\n",
    "        # get the image name\n",
    "        image_name = dataset.map(lambda image, image_name, target: image_name).unbatch()\n",
    "        image_name = next(iter(image_name.batch(number_of_files))).numpy().astype('U')\n",
    "        # get the real target\n",
    "        target = dataset.map(lambda image, image_name, target: target).unbatch()\n",
    "        target = next(iter(target.batch(number_of_files))).numpy()\n",
    "        # predict the validation set\n",
    "        image = dataset.map(lambda image, image_name, target: image)\n",
    "        probabilities = model.predict(image)\n",
    "        oof_image_name.extend(list(image_name))\n",
    "        oof_target.extend(list(target))\n",
    "        oof_prediction.extend(list(np.concatenate(probabilities)))\n",
    "    \n",
    "    print('\\n')\n",
    "    print('-'*50)\n",
    "    # save oof predictions\n",
    "    oof_df = pd.DataFrame({'image_name': oof_image_name, 'target': oof_target, 'predictions': oof_prediction})\n",
    "    oof_df.to_csv('EfficientNetB3_384.csv', index = False)\n",
    "        \n",
    "    # since we are splitting the dataset and iterating separately on images and ids, order matters.\n",
    "    test_ds = get_test_dataset(TEST_FILENAMES, labeled = False, ordered = True)\n",
    "    test_images_ds = test_ds.map(lambda image, image_name: image)\n",
    "    \n",
    "    print('Computing predictions...')\n",
    "    probabilities = np.average([np.concatenate(models[i].predict(test_images_ds)) for i in range(folds)], axis = 0)\n",
    "    print('Generating submission.csv file...')\n",
    "    test_ids_ds = test_ds.map(lambda image, image_name: image_name).unbatch()\n",
    "    # all in one batch\n",
    "    test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n",
    "    pred_df = pd.DataFrame({'image_name': test_ids, 'target': probabilities})\n",
    "    SUB.drop('target', inplace = True, axis = 1)\n",
    "    SUB = SUB.merge(pred_df, on = 'image_name')\n",
    "    SUB.to_csv('submission.csv', index = False)\n",
    "    print('Submission file generated')\n",
    "    \n",
    "    return oof_target, oof_prediction\n",
    "    \n",
    "oof_target, oof_prediction = train_and_predict(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
